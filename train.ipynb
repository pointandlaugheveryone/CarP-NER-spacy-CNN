{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Document import Document, Label\n",
    "from typing import List\n",
    "\n",
    "import json, rich\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "from IPython.display import display as ipy_display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c887ba3",
   "metadata": {},
   "source": [
    "##### previously used (openai for labeling)\n",
    "- too many incorrectly labeled examples, but quicker than using an entity ruler for preannotation\n",
    "```py\n",
    "def clean(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \"\").replace(\"\\t\", \" \")\n",
    "    text = re.sub('\\\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "resumes = []\n",
    "for file in tqdm(os.listdir(f'{os.getcwd()}/DATA/data_en')):\n",
    "    with open(f'{os.getcwd()}/DATA/data_en/{file}','r') as f:\n",
    "        contents = clean(f.read())\n",
    "        resumes.append(contents)\n",
    "\n",
    "\n",
    "labeled_resumes = []\n",
    "for i in tqdm(range(len(resumes[:500]))):\n",
    "    text = resumes[i]\n",
    "    api_labels = await send_request(text)\n",
    "\n",
    "    labels = []\n",
    "    for l in api_labels or []:\n",
    "        label = l['type']\n",
    "        content = l['text']\n",
    "        start = text.find(content)\n",
    "        if start == -1:\n",
    "            continue\n",
    "        end = start + len(content)\n",
    "        labels.append(Label(start,end,label,content).to_dict())\n",
    "\n",
    "    doc = Document(i,text,labels).to_dict()\n",
    "    labeled_resumes.append(doc)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3647f14",
   "metadata": {},
   "source": [
    "##### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80582e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DATA/docs_12.json','r') as j:\n",
    "    labeled_resumes = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22195d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_resumes = []\n",
    "i = 0\n",
    "\n",
    "for d in labeled_resumes:\n",
    "    text, labels = d[0], d[1]\n",
    "    text = text.replace(\"\\n\", \"-n\").replace(\"\\r\", \"-r\").replace(\"\\t\", \"-t\")\n",
    "    clean_labels = []\n",
    "    starts = []\n",
    "\n",
    "    for l in labels:\n",
    "        start, end, label, value = l[0], l[1], l[2], l[3]\n",
    "        \n",
    "        if (start in starts) or label=='Certification':\n",
    "            continue\n",
    "\n",
    "        starts.append(start)\n",
    "        clean_labels.append(Label(start,end,label,value).to_dict())\n",
    "\n",
    "    cleaned_resumes.append(Document(i,text,clean_labels).to_dict())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd67ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_resumes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5955195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(cleaned_resumes, test_size=0.1, random_state=707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b897c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(span1, span2):\n",
    "    return not (span1.end <= span2.start or span2.end <= span1.start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec14cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data: List[dict], output_name: str):\n",
    "    invalid_count, ent_count = 0, 0\n",
    "    nlp = spacy.blank('en')\n",
    "    doc_bin = DocBin()\n",
    "\n",
    "    for d in data:\n",
    "        text, labels = d['content'],d[\"labels\"]\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for l in labels:\n",
    "            start, end, label, value = l[\"start\"], l[\"end\"], l[\"label\"], l[\"value\"]\n",
    "            span = doc.char_span(start, end, label=label,alignment_mode='expand')\n",
    "            if span is None:\n",
    "                invalid_count += 1\n",
    "                continue\n",
    "            elif any(has_overlap(span, existing_span) for existing_span in ents):\n",
    "                span = doc.char_span(start, end, label=label,alignment_mode='contract')\n",
    "                if span is None:\n",
    "                    invalid_count += 1\n",
    "                    continue\n",
    "        \n",
    "            ents.append(span)\n",
    "                \n",
    "        ent_count += len(ents)\n",
    "        doc.ents = filter_spans(ents)\n",
    "        doc_bin.add(doc) \n",
    "    print(invalid_count, ent_count)\n",
    "    doc_bin.to_disk(f\"{output_name}.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(train,'train')\n",
    "preprocess(test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_whitespace(input_path):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc_bin = DocBin().from_disk(input_path)\n",
    "    filtered_doc_bin = DocBin()\n",
    "\n",
    "    for doc in doc_bin.get_docs(nlp.vocab):\n",
    "        filtered_ents = []\n",
    "        for ent in doc.ents:\n",
    "            if not (ent.text.startswith(\" \") or ent.text.endswith(\" \")):\n",
    "                filtered_ents.append(ent)\n",
    "        doc.ents = filtered_ents\n",
    "        filtered_doc_bin.add(doc)\n",
    "\n",
    "    filtered_doc_bin.to_disk(input_path)\n",
    "\n",
    "filter_whitespace(\"train.spacy\")\n",
    "filter_whitespace(\"test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56aa4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
      "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Language: en\n",
      "Training pipeline: tok2vec, ner\n",
      "1212 training docs\n",
      "135 evaluation docs\n",
      "\u001b[38;5;2m✔ No overlap between training and evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train a new pipeline (1212)\u001b[0m\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1152316 total word(s) in the data (41082 unique)\u001b[0m\n",
      "\u001b[38;5;4mℹ No word vectors present in the package\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 2 label(s)\u001b[0m\n",
      "0 missing value(s) (tokens with '-' label)\n",
      "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 7 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 1 warning\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy debug data config.cfg --paths.train ./train.spacy --paths.dev ./test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9508434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: spacy_outputs\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    419.10    0.76    0.86    0.68    0.01\n",
      "  0     200        229.05  24592.31    0.00    0.00    0.00    0.00\n",
      "  0     400        321.51  18028.61    1.09   46.05    0.55    0.01\n",
      "  0     600        364.96  18220.97    9.90   45.58    5.55    0.10\n",
      "  0     800        442.90  17772.90    6.85   51.10    3.67    0.07\n",
      "  0    1000        543.13  16440.35    1.93   66.67    0.98    0.02\n",
      "  0    1200        464.97  16134.82   11.91   52.15    6.72    0.12\n",
      "  1    1400        562.18  16606.81   15.16   50.09    8.93    0.15\n",
      "  1    1600        654.99  16978.79    9.66   60.04    5.25    0.10\n",
      "  1    1800        706.21  17127.25    8.23   58.33    4.43    0.08\n",
      "  1    2000        636.10  15959.06   13.58   52.00    7.81    0.14\n",
      "  1    2200       4139.93  17484.77   13.23   54.46    7.53    0.13\n",
      "  1    2400        769.91  16355.91   14.54   51.64    8.46    0.15\n",
      "  2    2600        947.52  16450.35   10.22   55.19    5.63    0.10\n",
      "  2    2800       1023.89  17747.70   13.94   54.00    8.00    0.14\n",
      "  2    3000        939.83  16021.39   16.50   52.10    9.80    0.17\n",
      "  2    3200       1041.59  15727.80   13.03   54.61    7.40    0.13\n",
      "  2    3400        947.10  15775.00   16.09   53.92    9.46    0.16\n",
      "  2    3600        907.31  16159.44   16.59   52.49    9.85    0.17\n",
      "  3    3800       1060.60  15457.06   12.95   55.24    7.34    0.13\n",
      "  3    4000       1130.02  15948.28   10.31   57.37    5.66    0.10\n",
      "  3    4200       1274.93  17038.74   15.62   52.58    9.17    0.16\n",
      "  3    4400       1235.30  15941.93   13.89   54.85    7.95    0.14\n",
      "  3    4600       1371.29  16235.87   16.62   52.26    9.88    0.17\n",
      "  3    4800       1173.91  15536.77   17.11   50.98   10.28    0.17\n",
      "  4    5000       1545.67  17039.89   19.86   46.56   12.62    0.20\n",
      "  4    5200       1513.27  15908.49   18.23   47.85   11.26    0.18\n",
      "  4    5400       1519.44  15408.23   15.86   53.45    9.31    0.16\n",
      "  4    5600       1671.39  16449.89   12.42   58.93    6.94    0.12\n",
      "  4    5800       1624.58  15280.33    9.51   63.73    5.14    0.10\n",
      "  4    6000       1519.52  15990.97   12.37   61.53    6.88    0.12\n",
      "  5    6200       1987.27  15264.91   17.91   49.36   10.94    0.18\n",
      "  5    6400       2077.47  16029.64   17.16   53.25   10.23    0.17\n",
      "  5    6600       2058.45  15342.50   15.58   55.58    9.06    0.16\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "spacy_outputs/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./spacy_outputs --paths.train ./train.spacy --paths.dev ./test.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
