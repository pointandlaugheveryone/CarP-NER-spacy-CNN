{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea14c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading full_matcher ...\n",
      "loading abv_matcher ...\n",
      "loading full_uni_matcher ...\n",
      "loading low_form_matcher ...\n",
      "loading token_matcher ...\n"
     ]
    }
   ],
   "source": [
    "import os, json, rich\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from skillNer.general_params import SKILL_DB\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "\n",
    "# nlp = spacy.load('spacy_outputs/model-best')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717c5ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m pre_ann = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m r[:\u001b[32m500\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     annotations = \u001b[43mskill_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     pre_ann.append(annotations)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mpreannotated.json\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m j:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CarP/ner-spacy-v2/ner-env/lib/python3.13/site-packages/skillNer/skill_extractor_class.py:129\u001b[39m, in \u001b[36mSkillExtractor.annotate\u001b[39m\u001b[34m(self, text, tresh)\u001b[39m\n\u001b[32m    123\u001b[39m skills_abv, text_obj = \u001b[38;5;28mself\u001b[39m.skill_getters.get_abv_match_skills(\n\u001b[32m    124\u001b[39m     text_obj, \u001b[38;5;28mself\u001b[39m.matchers[\u001b[33m'\u001b[39m\u001b[33mabv_matcher\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    126\u001b[39m skills_uni_full, text_obj = \u001b[38;5;28mself\u001b[39m.skill_getters.get_full_uni_match_skills(\n\u001b[32m    127\u001b[39m     text_obj, \u001b[38;5;28mself\u001b[39m.matchers[\u001b[33m'\u001b[39m\u001b[33mfull_uni_matcher\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m skills_low_form, text_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mskill_getters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_low_match_skills\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmatchers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlow_form_matcher\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m skills_on_token = \u001b[38;5;28mself\u001b[39m.skill_getters.get_token_match_skills(\n\u001b[32m    133\u001b[39m     text_obj, \u001b[38;5;28mself\u001b[39m.matchers[\u001b[33m'\u001b[39m\u001b[33mtoken_matcher\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    134\u001b[39m full_sk = skills_full + skills_abv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CarP/ner-spacy-v2/ner-env/lib/python3.13/site-packages/skillNer/matcher_class.py:332\u001b[39m, in \u001b[36mSkillsGetter.get_low_match_skills\u001b[39m\u001b[34m(self, text_obj, matcher)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m match_id, start, end \u001b[38;5;129;01min\u001b[39;00m matcher(doc):\n\u001b[32m    330\u001b[39m     id_ = matcher.vocab.strings[match_id]\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtext_obj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m]\u001b[49m.is_matchable:\n\u001b[32m    333\u001b[39m         skills.append({\u001b[33m'\u001b[39m\u001b[33mskill_id\u001b[39m\u001b[33m'\u001b[39m: id_+\u001b[33m'\u001b[39m\u001b[33m_lowSurf\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    334\u001b[39m                        \u001b[33m'\u001b[39m\u001b[33mdoc_node_value\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(doc[start:end]),\n\u001b[32m    335\u001b[39m                        \u001b[33m'\u001b[39m\u001b[33mdoc_node_id\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(start, end)),\n\u001b[32m    336\u001b[39m                        \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mlw_surf\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m skills, text_obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CarP/ner-spacy-v2/ner-env/lib/python3.13/site-packages/skillNer/text_class.py:304\u001b[39m, in \u001b[36mText.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     index: \u001b[38;5;28mint\u001b[39m\n\u001b[32m    280\u001b[39m ) -> Word:\n\u001b[32m    281\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"To get the word at the specified position by index\u001b[39;00m\n\u001b[32m    282\u001b[39m \n\u001b[32m    283\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m \u001b[33;03m    english\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlist_words\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "with open('en.txt','r') as f:\n",
    "    r = json.loads(f.read())\n",
    "\n",
    "pre_ann = []\n",
    "i = 0\n",
    "for doc in r[21:-1]:\n",
    "    if i == 21:\n",
    "    annotations = skill_extractor.annotate(doc)\n",
    "    pre_ann.append(annotations)\n",
    "\n",
    "with open('preannotated.json','w') as j:\n",
    "    j.write(json.dumps(pre_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5368aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_ann))\n",
    "# rich.print(pre_ann)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
