{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7ed56c",
   "metadata": {},
   "source": [
    " Testing output from an api run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_models import Entity, Labels\n",
    "import rich, json\n",
    "from openai import AzureOpenAI\n",
    "import azure.keyvault.secrets as azk\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os, asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(keyname):\n",
    "    vault_uri = 'https://keyvault-labeling.vault.azure.net/'\n",
    "    client = azk.SecretClient(vault_uri, DefaultAzureCredential())\n",
    "    secret = client.get_secret(keyname)\n",
    "    key = secret.value\n",
    "    return key\n",
    "\n",
    "async def send_request(filepath:str):\n",
    "    with open(filepath,'r') as f:\n",
    "        contents = f.read().replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    key = get_key('openai-key')\n",
    "    endpoint = 'https://labeling-llm-0.openai.azure.com/openai/deployments/gpt-4.1-nano/chat/completions?api-version=2025-01-01-preview'\n",
    "    client = AzureOpenAI(\n",
    "    azure_endpoint = endpoint,\n",
    "    api_key=key,\n",
    "    api_version=\"2024-12-01-preview\"\n",
    "    )\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a Named Entity Recognition (NER) model used as an advanced ATS scanner.\n",
    "                Your job is to extract words matching the specified entity types; soft skill, Capability, Personality trait, Job title. \n",
    "                Skip words not matching any of these types with well enough accuracy that a human would categorise them the same.\n",
    "                Only assign labels if youre certain that they are relevant in the job market and fall under one of specified categories with well enough accuracy.\n",
    "                Do not reformat or translate the text you find in the original document in any way.\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": contents,\n",
    "            }\n",
    "        ],\n",
    "        response_format=Labels,\n",
    "        n=1,\n",
    "\n",
    "    )\n",
    "    \n",
    "    message = completion.choices[0].message\n",
    "    if (message.refusal):\n",
    "        print(f'error in request at file {filepath}:\\n{message.refusal}\\n\\n{message}')\n",
    "        return 0\n",
    "    else:\n",
    "        labels = Labels.model_validate(message.parsed).model_dump()['Entities']\n",
    "        return (contents, labels)\n",
    "\n",
    "\n",
    "obj = await send_request(f'{os.getcwd()}/DATA/data_cs/1.txt')\n",
    "contents = obj[0].replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \") # type: ignore\n",
    "labels = obj[1] # type: ignore\n",
    "rich.print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d949738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_models import Label, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_entities(doc_contents:str,labels_list:list,doc_id:int=0):\n",
    "    doc = doc_contents.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \")\n",
    "    entities = labels_list\n",
    "    labeled_ents = []\n",
    "    for entity in entities:\n",
    "        content = entity['text']\n",
    "        label = entity['type']\n",
    "        if content not in doc_contents:\n",
    "            continue\n",
    "        else:\n",
    "            start = doc_contents.find(content)\n",
    "            end = start + len(content)\n",
    "            labeled_ent = Label(start,end,label,content).to_dict()\n",
    "            labeled_ents.append(labeled_ent)\n",
    "    labeled_doc = Document(doc_id,doc_contents, labeled_ents).to_dict()\n",
    "    return labeled_doc\n",
    "\n",
    "test_doc = format_entities(contents,labels)\n",
    "rich.print(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27264a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def check_duplicates(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for entry in data:\n",
    "        if \"labels\" in entry and isinstance(entry[\"labels\"], list):\n",
    "            labels = entry[\"labels\"]\n",
    "            seen = set()\n",
    "            duplicates = []\n",
    "            \n",
    "            for label in labels:\n",
    "                label_tuple = tuple(label.items())  # Convert dict to tuple for hashable comparison\n",
    "                if label_tuple in seen:\n",
    "                    duplicates.append(label)\n",
    "                else:\n",
    "                    seen.add(label_tuple)\n",
    "            \n",
    "            if duplicates:\n",
    "                print(f\"Duplicates found in entry ID {entry.get('id')}:\")\n",
    "                for duplicate in duplicates:\n",
    "                    print(duplicate)\n",
    "\n",
    "check_duplicates(f'{os.getcwd()}/DATA/labels_en_duplicates.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{os.getcwd()}/DATA/labels_en_duplicates.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "new_data = []\n",
    "for d in data:\n",
    "    debug_id = d[\"id\"]\n",
    "    doc = d[\"content\"]\n",
    "    ents = d[\"labels\"]\n",
    "    new_ents = []\n",
    "    seen = set()\n",
    "    \n",
    "    for ent in ents:\n",
    "        start, end, label, value = ent[\"start\"], ent[\"end\"], ent[\"label\"], ent[\"value\"]\n",
    "        \n",
    "        label_tuple = (start, end, label, value)\n",
    "        \n",
    "        if label_tuple in seen:\n",
    "            continue \n",
    "        else:\n",
    "            seen.add(label_tuple) \n",
    "    \n",
    "    new_data.append(Document(debug_id, doc, new_ents).to_dict())\n",
    "\n",
    "\n",
    "jsonfile = json.dumps(new_data, indent=4)\n",
    "with open('labels_en.json', 'w') as j:\n",
    "    j.write(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplicates('labels_en.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
